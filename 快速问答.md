# # 快速问答

## # 分类相关

### 一、基本问题

- **1、为什么分类要编码？ 分类的独热编码是什么？ 它解决了普通分类编码 （分类标为0，1，2，...）的什么问题？**

​	 因为数据分类的类别很多，计算机训练数据时又需要数值型的数据，所以需要分类编码；

​	独热编码是数据的每一个分类只占一个编码，且编码数值为1，其他为0

​	主要解决了普通分类编码的不一致性问题，如果存在1,2...，计算机会误认为这些类别是有序的



- **2、pd.get_dummies也可以把分类转成独热编码，它和sklearn的OneHotEncoder的核心区别是什么？**

​		pandas的get_dummies不能处理分类列表中分类不存在的数据



- **3、假设你要将图片分类为室外/室内和白天/夜间。你应该实现两个逻辑回归分类器还是一个softmax回归分类器？**

​		两个逻辑回归分类器较好，因为逻辑回归支持多标签分类。softmax仅适用于单标签多分类问题



### 二、混淆矩阵

- **1、简述下混淆矩阵是什么？**

​		混淆矩阵是机器学习中表示两个类别是否混淆的标志，它的每一行表示实际值，每一列表示预测值



- **2、简述下各个性能指标的意思： 准确率，召回率，F1分数，假阳性，PR曲线，ROC曲线，AUC分数**

​	**:one:准确率、召回率和F1分数**定义如下
$$
准确率 & \text{precision} = \frac{TP}{TP + FP} \\ \\
召回率 & \text{recall} = \frac{TP}{TP + FN} \\ \\
F1分数 & F_1 = \ \frac{2}{\frac{1}{\text{precision}} + \frac{1}{\text{recall}}} = \frac{2*TP}{2*TP + FP + FN}
$$
其中：TP代表真阳性（实际值为阳性，预测也为阳性），FP代表假阳性（实际值为阳性，预测为阴性），FN为假阴性率（实际值为阴性，预测为阳性），还有未提到的TN，代表真阴性（实际值为阴性，预测也为阴性）



**:two:PR曲线**：精确度-召回率曲线，显示了不同阈值下精确率和召回率之间的权衡，曲线下面积越大，表示召回率和精确率都越高。高准确率指的是返回结果中假阳性较少，而高召回率是指相关结果中假阴性较少，两者得分均较高，表明分类器返回的结果准确。**



**:three:ROC曲线与AUC分数**

ROC曲线的横轴为假阳性率FPR，纵轴为真阳性率（即召回率），定义如下
$$
假阳性率 & FPR = \frac{FP}{FP+TN} \\ \\
真阳性率 & TPR = \frac{TP}{TP+FN}
$$
AUC曲线为ROC曲线下方的面积，AUC面积越接近1模型预测效果越好





- **3、简述下准确率-召回率权衡**

​		准确率和召回率一般是此消彼长的关系，准确率的提高一般要通过提高分类阈值来实现，而提高召回率要通过降低分类阈值来实现，所以要进行准确率-召回率的权衡



- **4、如何用二元分类器 去解决多元分类的问题**

​	使用多个二元分类器组合成一个多元分类器



- **5、什么是 多标签-多分类问题？**

​	它允许每个样本同时属于多个类别标签，不在局限于一个样本一个类别标签







## # 回归相关

- **1、假设你正在使用多项式回归。绘制学习曲线后，你会发现训练误差和验证误差之间存在很大的差距。发生了什么？解决此问题的三种方法是什么？**

​		发生了模型过拟合的现象，使模型的泛化性能很差。

​		解决此问题的三种方法为：减少多项式的项数，增加训练集样本的数量，使用正则化项



- **2、假设你正在使用岭回归，并且你注意到训练误差和验证误差几乎相等且相当高。你是否会说模型存在高偏差或高方差？你应该增加正则化超参数α还是减小它呢？**

​		模型存在高偏差，减小正则化参数



- **3、为什么要使用：**

  - **a.岭回归而不是简单的线性回归（即没有任何正则化）？**

    ​    防止模型过拟合，正则化项惩罚权重大的特征

  - **b.Lasso而不是岭回归？**

    ​	Lasso的L1正则化能产生稀疏解（部分系数 = 0），适合特征选择

  - **c.弹性网络而不是Lasso回归？**

​					弹性网络（L1 + L2）结合了两者的优点，避免了 Lasso 在强相关性特征下的不稳定选择

​		



## # 模型性能评估相关

- **1、什么是k折交叉验证？  验证是在评估什么？**

​		将原始的数据集均分为k个子集，之后依次选择第 `i` $(i = 1,2,3， ...k)$个子集作为验证集，并将剩下的`k-1`个作为训练集；

​		此方法用于评估模型的泛化能力



- **2、精确率是什么，评估分类的性能为什么不能只用精确率？**

​		分类的精确率是混淆矩阵中的 TP / (TP + FP)，当阳性样本数量很少时（极端情况下1个），那么精确率可以达到100%，这不具有代表性





## # 梯度下降相关

- **1、如果你让它们运行足够长的时间，是否所有的梯度下降算法都能得出相同的模型？**

​		答案是否；因为梯度下降算法的超参数还有学习率，正则化强度等，就单拿学习率来说，如果学习率调的过大，则损失函数不会收敛到一个最小值，返回可能会使损失函数的值发散，若迭代次数足够多，甚至可以发散到无穷大



- **2、假设你使用批量梯度下降，并在每个轮次绘制验证误差。如果你发现验证错误持续上升，那么可能是什么情况？你该如何解决？**

​		可能是学习率过大或者过拟合的原因，降低学习率或者添加正则项

​	

- **3、当验证误差上升时立即停止小批量梯度下降是个好主意吗？**

​		不是，在小批量梯度下降的情况下，可能用于梯度更新的那一部分训练集样本恰好是噪声数据



- **4、训练逻辑回归模型时，梯度下降可能会卡在局部最小值中吗？**

​		不会，logistic回归的交叉熵损失函数为凸函数，只有一个全局最小值



- **5、哪种梯度下降算法将最快地到达最佳解附近？哪个实际上会收敛？如何使其他的也收敛**

​		SGD（随机梯度下降）会最快到达最优解；批量梯度下降实际上会收敛





## # SVM相关

- **1、支持向量机的基本思想是什么？**

​		寻找一个最优的决策超平面，使得分类数据的间隔尽可能大



- **2、什么是支持向量？**

​		支持向量是SVM中决定决策超平面的关键训练样本。

​		在SVC中，支持向量为位于间隔边界或误分类的样本。而SVR中，支持向量是位于决策边界带之外的样本



- **3、在使用 SVM 时，缩放输入值为什么很重要？**

​		因为SVM对特征的尺度敏感，默认的RBF核就依赖于样本之间的距离，如果未缩放到同一范围，则数值大的特征占主导



- **4、SVM 分类器在对实例进行分类时能输出置信度分数吗？概率呢？**

​		可以通过`decision_function()`输出置信度分数；

​		概率一般不会输出，可以显式的设置`probabilty = True`来对概率进行估计，但是这些概率估计是使用昂贵的五折交叉验证计算的



- **5、你如何在 LinearSVC、SVC 和 SGDClassifier 之间进行选择？**

​		LinearSVC 和 SVC 都适合中小型数据集，而LinearSVC仅适合线性可分的分类数据，SVC可以对非线性可分的数据进行分类

​		SGDClassifier 适合大规模的数据集，灵活度高



- **6、假设你已经使用 RBF 核训练了一个 SVM 分类器，但它似乎欠拟合训练集。你应该增大还是减小 γ（gamma）？C 呢？**

​		增大 $\gamma$，使核函数更敏感，决策边界更复杂，可以是模型更贴合训练数据

​		增大惩罚因子 C， 减少误分类的情况



- **7、ε 不敏感模型是什么意思？**

​		预测值与真实值的误差在 ε 以内时不计算损失，$\epsilon$越大，模型越简单



- **8、使用核技巧有什么意义？**

​		解决决策边界非线性的问题，由于核函数的可以将特征映射到高维空间中，因此在低维空间中线性不可分的数据，可能在高维空间中变的线性可分









## # 杂项

- **1、如果你的训练集具有数百万个特征，那么可以使用哪种线性回归训练算法？**

​		随机梯度下降和小批量梯度下降



- **2、如果你的训练集里特征的数值大小迥异，那么哪些算法可能会受到影响？受影响程度如何？你应该怎么做？**

​		梯度下降类算法会受到影响，例如线性回归、逻辑回归等，其损失值下降的时候会走 "之" 字型路线，需要很大的迭代次数才能收敛到最小值；还有例如KNN/SVM这种相似度敏感的算法。

​		 解决办法：样本特征标准化，必要的时候可以增加正则化项











