# # 快速问答

- **1、为什么分类要编码？ 分类的独热编码是什么？ 它解决了普通分类编码 （分类标为0，1，2，...）的什么问题？**

​	 因为数据分类的类别很多，计算机训练数据时又需要数值型的数据，所以需要分类编码；

​	独热编码是数据的每一个分类只占一个编码，且编码数值为1，其他为0

​	主要解决了普通分类编码的不一致性问题，如果存在1,2...，计算机会误认为这些类别是有序的



- **2、pd.get_dummies也可以把分类转成独热编码，它和sklearn的OneHotEncoder的核心区别是什么？**

​		pandas的get_dummies不能处理分类列表中分类不存在的数据



- **3、什么是k折交叉验证？  验证是在评估什么？**

​		将原始的数据集均分为k个子集，之后依次选择第 `i` $(i = 1,2,3， ...k)$个子集作为验证集，并将剩下的`k-1`个作为训练集；

​		此方法用于评估模型的泛化能力



- **4、精确率是什么，评估分类的性能为什么不能只用精确率？**

​		分类的精确率是混淆矩阵中的 TP / (TP + FP)，当阳性样本数量很少时（极端情况下1个），那么精确率可以达到100%，这不具有代表性



- **5、简述下混淆矩阵是什么？**

​		混淆矩阵是机器学习中表示两个类别是否混淆的标志，它的每一行表示实际值，每一列表示预测值



- **6、简述下各个性能指标的意思： 准确率，召回率，F1分数，假阳性，PR曲线，ROC曲线，AUC分数**

​	**:one:准确率、召回率和F1分数**定义如下
$$
准确率 & \text{precision} = \frac{TP}{TP + FP} \\ \\
召回率 & \text{recall} = \frac{TP}{TP + FN} \\ \\
F1分数 & F_1 = \ \frac{2}{\frac{1}{\text{precision}} + \frac{1}{\text{recall}}} = \frac{2*TP}{2*TP + FP + FN}
$$
其中：TP代表真阳性（实际值为阳性，预测也为阳性），FP代表假阳性（实际值为阳性，预测为阴性），FN为假阴性率（实际值为阴性，预测为阳性），还有未提到的TN，代表真阴性（实际值为阴性，预测也为阴性）



**:two:PR曲线**：精确度-召回率曲线，显示了不同阈值下精确率和召回率之间的权衡，曲线下面积越大，表示召回率和精确率都越高。高准确率指的是返回结果中假阳性较少，而高召回率是指相关结果中假阴性较少，两者得分均较高，表明分类器返回的结果准确。**



**:three:ROC曲线与AUC分数**

ROC曲线的横轴为假阳性率FPR，纵轴为真阳性率（即召回率），定义如下
$$
假阳性率 & FPR = \frac{FP}{FP+TN} \\ \\
真阳性率 & TPR = \frac{TP}{TP+FN}
$$
AUC曲线为ROC曲线下方的面积，AUC面积越接近1模型预测效果越好





- **7、简述下准确率-召回率权衡**

​		准确率和召回率一般是此消彼长的关系，准确率的提高一般要通过提高分类阈值来实现，而提高召回率要通过降低分类阈值来实现，所以要进行准确率-召回率的权衡





- **8、如何用二元分类器 去解决多元分类的问题**

​	使用多个二元分类器组合成一个多元分类器





- **9、什么是 多标签-多分类问题？**

​	它允许每个样本同时属于多个类别标签，不在局限于一个样本一个类别标签



 